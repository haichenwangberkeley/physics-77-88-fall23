{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee631914",
   "metadata": {},
   "source": [
    "# Homework 10 \n",
    "\n",
    "**Homework 9 was skipped**\n",
    "\n",
    "This homework assignment is due by 9:00 pm on Thursday, November 2, 2023\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9749924",
   "metadata": {},
   "source": [
    "# Problem 1 -  Binned Log likelihood Fit Revisted\n",
    "\n",
    "This problem is modified based on your feedback from Workshop 9 and our lecture discussion on Wednesday October 25. The new problem also allows you to improve the fit by incorporating numerical integration to the fit.\n",
    "\n",
    "Here we start with a review of the idea log likelihood fit:\n",
    "\n",
    "**What is a fit?**\n",
    "\"Fit\" refers to the process of fitting a statistical model to a set of data. It is about estimating the parameters of the model so that the model best explains the data that have been observed. During the lecture, we discussed how one may want to vary the mean and standard deviation of a normal function so that the normal function would be best aligned with the data, which is presented as a histogram.\n",
    "\n",
    "**Figure of merit: the negative log likelihood**\n",
    "To determine what parameter values make the model best fit the observed data, we need to define a figure of merit. In the lecture on hypothesis testing and parameter estimation, we introduced the likelihood function. The likelihood function tells you how likely the given model(PDF and the parameter values) is true given the observed data. When you found a set of parameters that maximized the likelihood function, one can consider the model fits the data best. The maximization of the likelihood function corresponds to the minimization of a negative log likelihood function. In summary, we need to vary the parameter values in the likelihood function to minimize the negative log likelihood in order to find the parameter values making the model fit the data the best.\n",
    "\n",
    "**Construct the Log likelihood function for this problem**\n",
    "As stated many times, a likelihood function has two set of parameters: the observation, which should be constant; the expection which are functions of variable parameters.\n",
    "\n",
    "In this problem, the data distribution is presented as a histogram with 20 bins in the range of (120,130). This means there are 20 statistically independent observations. The bin content (number of entries) in each one of the 20 bins is an observation, {$y_i$}. \n",
    "\n",
    "Now, we need to determine the expectation for each one of the 20 bins. A normal PDF is normalized to 1 when integrating over $x$. It gives the probability of an outcome appearing at a specific value of $x$. When the data sample has a total of $N$ entries, then the expectation for a bin starting from $x_i$ ending at $x_{i+1}$ is the integral of the normal function times the total number of entries in the data set:\n",
    "\n",
    "$\\large\n",
    "E_i = N \\cdot \\int_{x_i}^{x_{i+1}} f_{normal}(x,\\mu,\\sigma) dx\n",
    "$\n",
    "\n",
    "where $f_{normal}(x,\\mu,\\sigma)$ is a normal function of $x$ with a mean of $\\mu$ and a standard deviation of $\\sigma$\n",
    "\n",
    "In the workshop 9, we approximated this expectation as $N\\cdot f_{normal}(x_{c},\\mu,\\sigma) \\cdot \\omega$ where $x_{c}$ is the center of the bin, and $\\omega$ is the width of the bin.\n",
    "\n",
    "**What PDF/PMF should be used for each bin?**\n",
    "Regardless of the shape of the data distribution between 120 and 130, the number of entries in each bin should follow a Poisson distribution. This is because the expectation in a given bin would be constant corresponding to $\n",
    "E_i = N \\cdot \\int_{x_i}^{x_{i+1}} f_{normal}(x,\\mu,\\sigma) dx\n",
    "$\n",
    "\n",
    "As such, the likelihood function for a given bin would be\n",
    "\n",
    "$\\large\n",
    "{\\cal{L}}(y_i, E_i(\\mu,\\sigma,x_i, x_{i+1})) = Poisson(y_i, E_i(\\mu,\\sigma,x_i, x_{i+1})) \n",
    "$\n",
    "\n",
    "and the negative log likelihood function combining all the individual bins would be:\n",
    "\n",
    "$\\large\n",
    "-\\sum{\\mathrm{ln}{Poisson(y_i, E_i(\\mu,\\sigma,x_i, x_{i+1}))}}\n",
    "$\n",
    "\n",
    "note that there is no subscript for $\\mu$ or $\\sigma$ because they are parameters of the normal function and are the same for the whole dataset.\n",
    "\n",
    "\n",
    "**Requirement:**\n",
    "In this homework problem, you should use numerical integration to properly calculate the expectation, and determine the central values of $\\mu$ and $\\sigma$ with the negative log likelihood fit. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0bc180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Module needed for numerical integration\n",
    "from scipy.integrate import quad\n",
    "\n",
    "# Modules needed for PDF/PMFs\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import poisson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58294ea0",
   "metadata": {},
   "source": [
    "### Generate a dummpy dataset\n",
    "The cell below generate a dummy data sample. Do not modify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fb033c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not modify this cell\n",
    "np.random.seed(1050)\n",
    "data = np.random.normal(126,1.2,5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d52aae6",
   "metadata": {},
   "source": [
    "In the cell below, you have lines to histogram the data sample and draw its distribution. Pay attention to how the bincontent and bincenters were retrieved or calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5219bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the data sample\n",
    "# Google search this to understand what are the returning arguments from plt.hist()\n",
    "y, edges,_ = plt.hist(data, bins=20,range=(120,130))\n",
    "\n",
    "#y are the bin contents, edges are the edges of the bins, which you will need to perform numerical integration\n",
    "\n",
    "# This line gives you the bin centers. Why?\n",
    "x_c = (edges[:-1]+edges[1:])/2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67bb544",
   "metadata": {},
   "source": [
    "### Define a single bin integration function\n",
    "\n",
    "Define a fuinction that takes the mean $\\mu$ and standard deviation $\\sigma$ of the normal function, as well as the start and end points of an interval in $x$ as the input arguments, and this function returns the integral of the normal PDF from the lower edge of a bin to the upper edge of the bin, for the given values of $\\mu$ and $\\sigma$\n",
    "\n",
    "Verify your implementation is correct. For example, the integral of a normal PDF with mean of 145, and a sigma of 40, from x = 140 to x = 150 is 0.0994764496602258. Do you get the same answer?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef26c841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# 15 pts for properly calculating the integral and verifying the result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2651140",
   "metadata": {},
   "source": [
    "### Construct the negative log likelihood function for all the bins\n",
    "\n",
    "Earlier you were given a cell to retrieve the number of entries in each bin of the histogram, which are the observation. In the cell above, you constructed a function to calculate the PDF integral for a given bin that would be specified by the lower and upper edges of the bin. Now, you can follow the problem description to construct the negative log likelihood function for the full distribution. Do not forget to incorporate the total number of entries to your single bin expectation calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df737833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here \n",
    "# 20 pts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac99d71",
   "metadata": {},
   "source": [
    "### Executing the fit\n",
    "\n",
    "Now find the mean and standard deviation of the normal function that would minimize the negative log likelihood function that you just constructed. In this part, you would need to import minimize from scipy.optimize. Consult with workshop 9 and google search, if you need to understand what are the input arguments of the function minimize. \n",
    "\n",
    "Print out the fit favored values of $\\mu$ and $\\sigma$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f145633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# 10 pts for the minimization code\n",
    "# 5 pts for the proper presentation of fit favored mu and sigma "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efe7a2a",
   "metadata": {},
   "source": [
    "# Problem 2: Understanding the Characteristics of Numerical integration [Ayars 2.2]\n",
    "\n",
    "Compare results of the trapezoid integration method,  Simpson’s method, and the adaptive Gaussian quadrature method for the following integrals:\n",
    "\n",
    "1. $$\\int_0^{\\pi/2}\\cos x\\, dx $$\n",
    "1. $$\\int_1^3 \\frac{1}{x^2}\\, dx $$\n",
    "1. $$\\int_2^4 (x^2+x+1)\\, dx$$\n",
    "1. $$\\int_0^{6.9}\\cos\\left(\\frac{\\pi}{2}x^2\\right)\\, dx$$\n",
    "\n",
    "For each part, try it with more and with fewer slices to determine how many slices are required to give an ‘acceptable’ answer. (If you double the number of slices and still get the same answer, then try half as many, etc.) Parts (3) and (4) are particularly interesting in this regard. In your submitted work, describe roughly how many points were required, and explain. You may want to consult Workshop 10 if you are unsure about the technical implemention of these numerical integration methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d21476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "'''The best way to \"explain\" how many slices/points are needed to get an acceptable answer is to just\n",
    "   make plots of the fractional error vs number of slices.  The fractional error is defined as \n",
    "   abs(estimate - exact)/exact, where \"estimate\" is the value of the integral using one of these three\n",
    "   integration methods and \"exact\" is the analytical value of the integral (by hand or using WolframAlpha).\n",
    "   If you do everything correctly, you should find that the fractional error approaches 0 as you increase\n",
    "   the number of slices.'''\n",
    "\n",
    "\n",
    "# 1 pts for getting the correct exact value of the integral, for each case\n",
    "\n",
    "# 9 pts for plotting the fractional error vs number of intervals (slices), for each case\n",
    "# You don't need to specify the number of slices for the quad method (adaptive quadrature) \n",
    "# because it does it for you automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452e7e01",
   "metadata": {},
   "source": [
    "**Provide your analysis of these results here**\n",
    "\n",
    "10 pts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
